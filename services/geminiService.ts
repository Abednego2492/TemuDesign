
import { GoogleGenAI } from "@google/genai";
import { AspectRatio, DensityLevel, DesignContextType, Language, MagazineAnalysisResult, PosterStyleType, TextSuggestion } from "../types";

// --- CLIENT & BASICS ---

// Helper to initialize client with Optional Custom Key
const getClient = (customApiKey?: string) => {
    // Priority: Custom Key -> Env Key
    const key = customApiKey && customApiKey.trim() !== '' ? customApiKey : process.env.API_KEY;
    if (!key) {
        throw new Error("No API Key available. Please provide a key.");
    }
    // CRITICAL FIX: Force usage of 'v1beta' API version.
    // 'gemini-3-pro-image-preview' and other preview models often do not exist on the stable 'v1' endpoint yet.
    // This ensures cross-project access to preview models.
    return new GoogleGenAI({ apiKey: key, apiVersion: 'v1beta' });
};

// --- VALIDATION HELPER (NEW MODULAR FUNCTION) ---
export const validateCustomApiKey = async (apiKey: string): Promise<boolean> => {
    try {
        // Must use v1beta here as well to be consistent
        const ai = new GoogleGenAI({ apiKey: apiKey, apiVersion: 'v1beta' });
        // Perform a robust check using generateContent instead of countTokens
        await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [{ text: "Test connection" }] }
        });
        return true;
    } catch (e: any) {
        console.error("API Key Validation Failed:", e);
        // Throw the specific error message so the UI can display it (e.g. "API key not valid", "Quota exceeded")
        throw new Error(e.message || "Validation failed. Please check your API key permissions.");
    }
};

// --- MODEL SELECTOR ---
const getGenerativeModelName = (useProModel: boolean = false) => {
    // gemini-3-pro-image-preview is the mapping for "Nano Banana Pro"
    return useProModel ? 'gemini-3-pro-image-preview' : 'gemini-2.5-flash-image';
};


const cleanBase64 = (dataUrl: string) => {
  return dataUrl.split(',')[1];
};

const extractJSON = (text: string) => {
  try {
    const match = text.match(/```json\s*([\s\S]*?)\s*```/);
    if (match) {
      return JSON.parse(match[1]);
    }
    return JSON.parse(text);
  } catch (e) {
    console.error("Failed to parse JSON", e);
    return null;
  }
};

// --- IMAGE UTILS ---

const processImageResponse = (response: any) => {
    const candidates = response.candidates;
    if (candidates && candidates.length > 0) {
        for (const part of candidates[0].content.parts) {
            if (part.inlineData) {
                return `data:image/png;base64,${part.inlineData.data}`;
            }
        }
    }
    throw new Error("No image generated by Gemini.");
};

// --- HELPER: ROBUST GENERATION WITH FALLBACK ---
// This wrapper attempts the Pro model, and if it fails due to permissions (403/404),
// it falls back to the Flash model using the SAME custom key.
const safeGenerateImage = async (
    ai: GoogleGenAI,
    preferredModel: string,
    params: any
) => {
    try {
        // Attempt 1: Preferred Model (e.g., Pro)
        const response = await ai.models.generateContent({
            model: preferredModel,
            ...params
        });
        return processImageResponse(response);
    } catch (error: any) {
        // Check for common model availability/permission errors
        const isModelError = error.message?.includes('404') || 
                             error.message?.includes('403') || 
                             error.message?.includes('not found') ||
                             error.message?.includes('Publisher Model');

        // If we failed on the PRO model, try the FLASH model as fallback
        if (preferredModel === 'gemini-3-pro-image-preview' && isModelError) {
            console.warn(`Pro Model (${preferredModel}) failed with permission error. Falling back to 'gemini-2.5-flash-image'.`);
            try {
                const fallbackResponse = await ai.models.generateContent({
                    model: 'gemini-2.5-flash-image',
                    ...params
                });
                return processImageResponse(fallbackResponse);
            } catch (fallbackError: any) {
                // If fallback also fails, throw the fallback error
                throw new Error(`Generation failed: ${fallbackError.message || "Unknown error"}`);
            }
        }

        // If it wasn't a Pro model failure or unrelated error, throw original
        throw new Error(`Generation failed: ${error.message || "Unknown error"}`);
    }
};


// --- API FUNCTIONS ---

export const generatePosterTextSuggestions = async (
  imageBase64: string,
  density: DensityLevel,
  language: Language,
  style: PosterStyleType,
  customApiKey?: string
): Promise<TextSuggestion> => {
  const ai = getClient(customApiKey); // Support Custom Key for Analysis too
  const cleanedImage = cleanBase64(imageBase64);

  // LOGIC CRAFTING: STRUCTURAL DENSITY
  // Instead of just "more words", we define specific fields based on density.
  
  let requiredFields = `
    - headline: Main title (Max 5 words).
    - subheadline: Subtext 1 (Max 7 words).
    - body: Main body text (Max 10 words).
    - cta: Call to action.
    - tagline: Short punchy phrase.
  `;

  if (density >= 3) {
      requiredFields += `\n- highlights: 3 short bullet points (e.g., "Fast | Secure | Easy").`;
  }
  if (density >= 4) {
      requiredFields += `\n- subheadline_2: Secondary subtext or date/location info (Max 5 words).`;
  }
  if (density === 5) {
      requiredFields += `\n- body_2: Secondary description or testimonials (Max 8 words).`;
  }

  const prompt = `
    Analyze this product image and generate marketing copy for a ${style} poster.
    Language: ${language}.
    
    CRITICAL: Keep text SHORT and PUNCHY to avoid rendering errors. 
    Strictly follow the structure below based on Density Level ${density}.

    Required JSON Fields:
    ${requiredFields}
    
    Output Format: JSON ONLY.
  `;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: {
      parts: [
        { inlineData: { mimeType: 'image/png', data: cleanedImage } },
        { text: prompt }
      ]
    },
    config: { responseMimeType: 'application/json' }
  });

  return extractJSON(response.text || "{}") as TextSuggestion;
};

// --- BATCH GENERATION LOGIC ---

const constructVisualLayeringPrompt = (
    style: PosterStyleType, 
    textConfig: TextSuggestion
) => {
    // Helper to build a "Spatial Prompt" that maps text to layout regions.
    // This reduces "Bad Typo" risk by organizing the AI's attention.

    let textInstructions = `
    1. HEADLINE (Top/Center, Large): "${textConfig.headline}"
    2. SUBTEXT 1 (Near Headline): "${textConfig.subheadline}"
    3. TAGLINE (Creative Placement): "${textConfig.tagline}"
    4. BODY 1 (Middle/Side): "${textConfig.body}"
    5. CTA (Bottom, Distinct): "${textConfig.cta}"
    `;

    // Add high density fields if they exist
    if (textConfig.highlights) {
        textInstructions += `6. HIGHLIGHTS (Small/List format): "${textConfig.highlights}"\n`;
    }
    if (textConfig.subheadline_2) {
        textInstructions += `7. SUBTEXT 2 (Secondary Info): "${textConfig.subheadline_2}"\n`;
    }
    if (textConfig.body_2) {
        textInstructions += `8. BODY 2 (Additional Info): "${textConfig.body_2}"\n`;
    }

    return `
        Create a High-Quality Poster.
        Style: ${style}.
        
        >>> TEXT RENDERING INSTRUCTIONS (STRICT):
        Render the following text elements clearly. 
        Do not change the spelling. 
        Ensure contrast between text and background.
        
        ${textInstructions}
        
        >>> VISUAL COMPOSITION:
        - Integrate the product image seamlessly.
        - Use a layout that accommodates the text without overcrowding.
        - Hierarchy: Headline > Subtext > Body.
    `;
};

const generateSinglePoster = async (
    cleanedImage: string, 
    style: PosterStyleType, 
    textConfig: TextSuggestion, 
    aspectRatio: AspectRatio,
    useProModel: boolean,
    customApiKey?: string
) => {
    const ai = getClient(customApiKey);
    const modelName = getGenerativeModelName(useProModel);
    const prompt = constructVisualLayeringPrompt(style, textConfig);

    return safeGenerateImage(ai, modelName, {
        contents: {
            parts: [
                { inlineData: { mimeType: 'image/png', data: cleanedImage } },
                { text: prompt }
            ]
        },
        config: { imageConfig: { aspectRatio: aspectRatio } }
    });
};

export const generateBatchPosters = async (
  imageBase64: string,
  style: PosterStyleType,
  textConfig: TextSuggestion,
  aspectRatio: AspectRatio,
  count: number = 1,
  useProModel: boolean = false,
  customApiKey?: string
): Promise<string[]> => {
    const cleanedImage = cleanBase64(imageBase64);
    
    const promises = Array.from({ length: count }, () => 
        generateSinglePoster(cleanedImage, style, textConfig, aspectRatio, useProModel, customApiKey)
            .catch(e => {
                console.error("Batch item failed", e);
                return null;
            })
    );

    const results = await Promise.all(promises);
    return results.filter((img): img is string => img !== null);
};


// --- REFERENCE BATCH LOGIC ---

const generateSingleReferencePoster = async (
    cleanedProduct: string,
    cleanedRef: string,
    language: Language,
    aspectRatio: AspectRatio,
    useProModel: boolean,
    customApiKey?: string,
    cleanedLogo?: string
) => {
    const ai = getClient(customApiKey);
    const modelName = getGenerativeModelName(useProModel);
    
    const parts: any[] = [
        { inlineData: { mimeType: 'image/png', data: cleanedProduct } },
        { inlineData: { mimeType: 'image/png', data: cleanedRef } }
    ];

    if (cleanedLogo) {
        parts.push({ inlineData: { mimeType: 'image/png', data: cleanedLogo } });
    }

    const prompt = `
    Role: Senior Art Director.

    INPUTS:
    [Image 1] = HERO PRODUCT (Subject).
    [Image 2] = LAYOUT REFERENCE (Style/Structure).
    ${cleanedLogo ? "[Image 3] = BRAND LOGO." : ""}

    TASK:
    Clone the layout structure of [Image 2] but replace the subject with [Image 1].
    
    >>> TYPOGRAPHY & LAYOUT LOGIC:
    1. Analyze the text placement in [Image 2].
    2. REPLACE all original text with new, relevant marketing copy in ${language}.
    3. Ensure the text is perfectly legible (No gibberish).
    4. Maintain the font hierarchy (Bold headers, lighter body).
    
    >>> BRANDING:
    - Colors: Extract strictly from [Image 1] (Product).
    ${cleanedLogo ? "- Logo: Place [Image 3] in a standard logo position (Corner or Top Center)." : ""}
    
    Create a clean, professional output.
    `;

    parts.push({ text: prompt });

    return safeGenerateImage(ai, modelName, {
        contents: { parts: parts },
        config: { imageConfig: { aspectRatio: aspectRatio } }
    });
};

export const generateBatchReferencePosters = async (
  productImageBase64: string,
  referenceImageBase64: string,
  language: Language,
  aspectRatio: AspectRatio = "1:1",
  logoBase64: string | null = null,
  count: number = 1,
  useProModel: boolean = false,
  customApiKey?: string
): Promise<string[]> => {
    const cleanedProduct = cleanBase64(productImageBase64);
    const cleanedRef = cleanBase64(referenceImageBase64);
    const cleanedLogo = logoBase64 ? cleanBase64(logoBase64) : undefined;

    const promises = Array.from({ length: count }, () => 
        generateSingleReferencePoster(cleanedProduct, cleanedRef, language, aspectRatio, useProModel, customApiKey, cleanedLogo)
            .catch(e => {
                console.error("Batch reference item failed", e);
                return null;
            })
    );

    const results = await Promise.all(promises);
    return results.filter((img): img is string => img !== null);
};

// --- CREATIVE MANUAL BATCH LOGIC (ENHANCED) ---

interface CreativeTextPlan {
    main_headline: string;
    sub_headline: string;
    visual_description: string;
    color_palette_vibes: string;
    layout_style: string;
}

// 1. Helper function to generate the text content FIRST (The Brain)
const generateCreativeTextPlan = async (
    instruction: string,
    context: DesignContextType,
    customApiKey?: string
): Promise<CreativeTextPlan> => {
    const ai = getClient(customApiKey);
    const prompt = `
        You are a Creative Director. Plan a poster design based on this instruction.
        
        USER INSTRUCTION: "${instruction}"
        DESIGN CONTEXT: "${context}"
        
        Task: Return a JSON object defining the text and visual direction.
        Format:
        {
          "main_headline": "The primary title (short, punchy)",
          "sub_headline": "A descriptive subtitle or slogan",
          "visual_description": "Detailed description of the main visual imagery to generate",
          "color_palette_vibes": "Description of colors (e.g. Neon Blue & Black)",
          "layout_style": "Description of layout (e.g. Minimalist Grid)"
        }
    `;

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash', // Use Text model for logic
        contents: { parts: [{ text: prompt }] },
        config: { responseMimeType: 'application/json' }
    });

    return extractJSON(response.text || "{}") as CreativeTextPlan;
};

// 2. Helper function to construct the robust prompt (The Architect)
const constructPreciseLayeredPrompt = (
    plan: CreativeTextPlan,
    context: DesignContextType,
    originalInstruction: string
): string => {
    return `
    Role: World-Class Information Designer & Expert Typographer.
    
    >>> CRITICAL TASK:
    Create a poster for context: '${context}'.
    User Intent: "${originalInstruction}"

    >>> VISUAL INSTRUCTIONS (LAYER 1 & 2):
    - Subject: ${plan.visual_description}
    - Style: ${plan.layout_style}
    - Colors: ${plan.color_palette_vibes}
    - Quality: Photorealistic, 8k, Octane Render, or High-End Vector (depending on style).

    >>> TYPOGRAPHY INSTRUCTIONS (LAYER 3 - STRICT):
    You MUST render the following text content exactly as written. 
    Do NOT generate random text. 
    Spelling must be pixel-perfect.

    1. PRIMARY HEADLINE (Large, Bold):
       "${plan.main_headline}"
    
    2. SECONDARY TEXT (Readable, Clean):
       "${plan.sub_headline}"

    >>> COMPOSITION:
    - Ensure text has high contrast against the background.
    - Do not overlap text on busy visual elements.
    - Use a professional font hierarchy.
    `;
};

const generateSingleCreativePoster = async (
  prompt: string,
  aspectRatio: AspectRatio,
  useProModel: boolean,
  customApiKey?: string
) => {
  const ai = getClient(customApiKey);
  const modelName = getGenerativeModelName(useProModel);
  
  return safeGenerateImage(ai, modelName, {
      contents: {
          parts: [{ text: prompt }]
      },
      config: { imageConfig: { aspectRatio: aspectRatio } }
  });
};

export const generateCreativeBatchPosters = async (
  instruction: string,
  context: DesignContextType,
  aspectRatio: AspectRatio,
  count: number = 1,
  useProModel: boolean = false,
  customApiKey?: string
): Promise<string[]> => {
  
  // Step 1: Generate the Text Plan (Once) to ensure consistency or correct spelling
  const textPlan = await generateCreativeTextPlan(instruction, context, customApiKey);
  
  // Step 2: Construct the robust prompt
  const robustPrompt = constructPreciseLayeredPrompt(textPlan, context, instruction);

  console.log("Generated Prompt:", robustPrompt); // Debugging

  // Step 3: Batch Generate
  const promises = Array.from({ length: count }, () => 
      generateSingleCreativePoster(robustPrompt, aspectRatio, useProModel, customApiKey)
          .catch(e => {
              console.error("Batch creative item failed", e);
              return null;
          })
  );

  const results = await Promise.all(promises);
  return results.filter((img): img is string => img !== null);
};

// --- MAGAZINE ANALYSIS & VISION OCR ---

export const analyzeMagazineLayout = async (
  imageBase64: string,
  customApiKey?: string
): Promise<MagazineAnalysisResult> => {
  const ai = getClient(customApiKey);
  const cleanedImage = cleanBase64(imageBase64);

  const prompt = `
    ROLE: Enhanced Vision AI & Senior Design Analyst.
    
    TASK: 
    Analyze the attached image (magazine or poster). 
    Perform highly accurate OCR (Optical Character Recognition) and Structure Analysis.
    
    1. EXTRACT ALL TEXT visible in the image.
    2. CLASSIFY the text into a proper Magazine/Design hierarchy.
       - Headline: The largest, most dominant text.
       - Subtext 1: Secondary headers or kickers.
       - Subtext 2: Smaller supporting text or captions.
       - Body: Paragraph text or long descriptions.
       - CTA: Call to Action (buttons, contact info, websites).
    3. ANALYZE VISUAL STYLE: Describe the color palette, font styles, and layout composition.
    4. GENERATE A PROMPT: Create a highly detailed prompt that would generate a *new* design with the *exact same text structure* and visual vibe.
    
    OUTPUT:
    Return a JSON object ONLY with the following keys:
    {
      "headline": "...",
      "subtext_1": "...",
      "subtext_2": "...",
      "body": "...",
      "cta": "...",
      "visual_style_description": "...",
      "recreation_prompt": "..."
    }
    
    If a field is empty in the image, return an empty string "".
  `;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: {
      parts: [
        { inlineData: { mimeType: 'image/png', data: cleanedImage } },
        { text: prompt }
      ]
    },
    config: { responseMimeType: 'application/json' }
  });

  return extractJSON(response.text || "{}") as MagazineAnalysisResult;
};

// --- AFFILIATOR MODE LOGIC ---

// Step 1: Analyze both images to understand physical traits and product details
export const analyzeAffiliatorInputs = async (
    personBase64: string,
    productBase64: string,
    customApiKey?: string
): Promise<{ personFeatures: string, productDetails: string }> => {
    const ai = getClient(customApiKey);
    const p1 = cleanBase64(personBase64);
    const p2 = cleanBase64(productBase64);

    const prompt = `
    Analyze these two images:
    Image 1: A Person. Describe their gender, hair style/color, approximate age, and body type in concise detail.
    Image 2: A Product. Describe exactly what it is (brand, packaging, color, material, text on label) so it can be recreated.

    Return JSON:
    {
        "personFeatures": "...",
        "productDetails": "..."
    }
    `;

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: {
            parts: [
                { inlineData: { mimeType: 'image/png', data: p1 } },
                { inlineData: { mimeType: 'image/png', data: p2 } },
                { text: prompt }
            ]
        },
        config: { responseMimeType: 'application/json' }
    });

    return extractJSON(response.text || "{}");
};

const generateSingleAffiliatorImage = async (
    personBase64: string,
    productBase64: string,
    scene: string,
    outfit: string,
    pose: string,
    analysis: { personFeatures: string, productDetails: string },
    aspectRatio: AspectRatio,
    useProModel: boolean,
    customApiKey?: string
) => {
    const ai = getClient(customApiKey);
    const modelName = getGenerativeModelName(useProModel);
    const p1 = cleanBase64(personBase64);
    const p2 = cleanBase64(productBase64);

    // SPECIALLY CRAFTED PROMPT FOR RAW AUTHENTIC / AMATEUR AESTHETIC
    const prompt = `
    Role: Amateur Content Creator / Social Media User (Non-Professional).
    Camera: Smartphone (iPhone 15 Pro Max or Samsung Galaxy), Raw Photo Mode.
    
    >>> TASK:
    Generate a 100% AUTHENTIC, RAW, UNEDITED user-generated photo.
    DO NOT generate a professional studio image.
    DO NOT make it look like an AI render.
    
    >>> SUBJECT & PRODUCT (MUST BE EXACT):
    - Subject: Person based on [Image 1] (${analysis.personFeatures}). 
    - Product: Authentic Item based on [Image 2] (${analysis.productDetails}). 
    - The product must be held/placed realistically, not floating.
    
    >>> SCENE & CONTEXT:
    - Environment: ${scene} (Make it look real, lived-in, not a sterile 3D set).
    - Outfit: ${outfit}.
    - Pose: ${pose}.
    
    >>> CRITICAL "RAW REALITY" VISUAL INSTRUCTIONS:
    1. IMPERFECT LIGHTING: Use natural, uneven lighting. Harsh shadows from the sun or indoor bulbs. High contrast. Avoid perfect soft-box studio lighting.
    2. SKIN TEXTURE: The person MUST have realistic skin texture (visible pores, slight unevenness, peach fuzz, moles). NO smooth "plastic" AI skin.
    3. HAIR TEXTURE: Frizzy strands, flyaways, not perfectly groomed.
    4. IMAGE QUALITY: High ISO noise/grain is acceptable. Slight motion blur on edges. Focus breathing.
    5. COLOR TONE: Natural, un-graded colors. Slightly desaturated or warm indoor tungsten, exactly how a phone camera captures reality.
    6. BACKGROUND: Realistic depth of field, objects in background should look casual/random (not perfectly arranged).
    
    The goal is for the viewer to believe this was taken casually with a phone 5 minutes ago.
    `;

    return safeGenerateImage(ai, modelName, {
        contents: {
            parts: [
                { inlineData: { mimeType: 'image/png', data: p1 } },
                { inlineData: { mimeType: 'image/png', data: p2 } },
                { text: prompt }
            ]
        },
        config: { imageConfig: { aspectRatio: aspectRatio } }
    });
};

export const generateAffiliatorMarketingImage = async (
    personBase64: string,
    productBase64: string,
    scene: string,
    outfit: string,
    pose: string,
    aspectRatio: AspectRatio,
    count: number = 1,
    useProModel: boolean = false,
    customApiKey?: string
): Promise<string[]> => {
    
    // Step 1: Pre-Analyze
    const analysis = await analyzeAffiliatorInputs(personBase64, productBase64, customApiKey);

    // Step 2: Batch Generate
    const promises = Array.from({ length: count }, () => 
        generateSingleAffiliatorImage(personBase64, productBase64, scene, outfit, pose, analysis, aspectRatio, useProModel, customApiKey)
            .catch(e => {
                console.error("Batch affiliator item failed", e);
                return null;
            })
    );

    const results = await Promise.all(promises);
    return results.filter((img): img is string => img !== null);
};
